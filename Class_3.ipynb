{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e2f729",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "* OCCAM: The best way to solve something is the simplest option.\n",
    "* Become the model more general. Avoid overfiting \n",
    "* Outlayer, the performance into set test is bad\n",
    "* Restrict the model capability \n",
    "* Figure-merit: MSE  + (factor alpha)*parameter number otimization\n",
    "    alpha: regularization factor (C)\n",
    "    C (maior) -> N.S.V (maior)\n",
    "* SVM LINEAR vs Perceptron transformation: There is a video.\n",
    "\n",
    "\n",
    "\n",
    "###### Sistema Especialista\n",
    "    Research    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a06e48",
   "metadata": {},
   "source": [
    "## Decision Tree \n",
    "* Gini critery: Confusion indicator. It's so important to regularate.\n",
    "    Hiperplane always orthogonally to axis feature\n",
    "\n",
    "    White Box Models vs Black Box Models\n",
    "Learnig Methods\n",
    "    -CART\n",
    "    -ID3\n",
    "    -Quilan C4.5\n",
    "Gini calculation: Transformation number in probability distribution \n",
    "    $G_i =1 -  \\sum_{k=1}^n p{i,k}^2$\n",
    "\n",
    "Shannon Entropy\n",
    "I ~ 1/p\n",
    "\n",
    "I = log_2 1/p bits, such that bits is a information unit. Entropy is value hope of information\n",
    "\n",
    "Cross Entropy\n",
    "\n",
    "bits vs nats (log_e)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
